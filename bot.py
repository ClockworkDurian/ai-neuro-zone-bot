import os
import sys
import logging
import asyncio
import time  # –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª–µ–Ω –∏–º–ø–æ—Ä—Ç –¥–ª—è –∑–∞–º–µ—Ä–∞ –≤—Ä–µ–º–µ–Ω–∏
import httpx
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, Message
from dotenv import load_dotenv

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows ===
sys.stdout.reconfigure(encoding='utf-8')

# === –õ–æ–≥–∏ ===
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# === –ó–∞–≥—Ä—É–∑–∫–∞ .env ===
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN") or os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROK_API_KEY = os.getenv("GROK_API_KEY") or os.getenv("XAI_API_KEY")
GROK_API_BASE = os.getenv("GROK_API_BASE", "https://api.x.ai/v1")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PROXY_URL = os.getenv("PROXY_URL")

bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()

# === –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∏—Å—Ç–æ—Ä–∏—è ===
user_state = {}
MAX_HISTORY_LENGTH = 10

# === –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –∏ –ú–æ–¥–µ–ª–∏ ===
def main_menu():
    buttons = [
        [InlineKeyboardButton(text="üí≠ ChatGPT (OpenAI)", callback_data="provider_openai")],
        [InlineKeyboardButton(text="üß† Grok (xAI)", callback_data="provider_grok")],
        [InlineKeyboardButton(text="‚ö° Gemini (Google)", callback_data="provider_gemini")],
        [InlineKeyboardButton(text="üåê –°–∞–π—Ç", url="https://neurozone.pro/")],
        [InlineKeyboardButton(text="üîí –ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏", url="https://neurozone.pro/privacy")],
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
openai_models = { "GPT-5": {"id": "gpt-5", "desc": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å..."}, "GPT-5 mini": {"id": "gpt-5-mini", "desc": "–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è..."}, "GPT-5 nano": {"id": "gpt-5-nano", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è..."}, "GPT-4.1": {"id": "gpt-4.1", "desc": "–°–∞–º–∞—è —É–º–Ω–∞—è..."}}
grok_models = {"Grok-code-fast-1": {"id": "grok-code-fast-1", "desc": "–ë—ã—Å—Ç—Ä–∞—è..."}, "Grok-4-fast-reasoning": {"id": "grok-4-fast-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ..."}, "Grok-4-fast-non-reasoning": {"id": "grok-4-fast-non-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ..."}}
gemini_models = {"Gemini 2.5 Flash": {"id": "gemini-2.5-flash", "desc": "–õ—É—á—à–∞—è..."},"Gemini 2.5 Flash-Lite": {"id": "gemini-2.5-flash-lite", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è..."}}


# === –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±—Ä–æ—Å–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏–∏ ===
def reset_user_state(user_id):
    user_state[user_id] = {"provider": None, "model": None, "history": []}


# === /start ===
@dp.message(Command("start"))
async def start_command(message: Message):
    reset_user_state(message.from_user.id)
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç *NeuroZone*.\n\n"
        "–Ø –∑–∞–ø–æ–º–∏–Ω–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞—à–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥, –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É /reset.\n\n"
        "–î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É /image (–Ω–∞–ø—Ä–∏–º–µ—Ä, `/image —Ä—ã–∂–∏–π –∫–æ—Ç –≤ –∫–æ—Å–º–æ—Å–µ`).\n\n"
        "–í—ã–±–µ—Ä–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å, —Å –∫–æ—Ç–æ—Ä–æ–π —Ö–æ—á–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å:",
        parse_mode="Markdown",
        reply_markup=main_menu()
    )

# === /reset ===
@dp.message(Command("reset"))
async def reset_command(message: Message):
    reset_user_state(message.from_user.id)
    await message.answer(
        "‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Å–±—Ä–æ—à–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥!\n\n–í—ã–±–µ—Ä–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å:",
        parse_mode="Markdown",
        reply_markup=main_menu()
    )


# –ù–û–í–´–ô –ë–õ–û–ö: –û–±—Ä–∞–±–æ—Ç—á–∏–∫ –∫–æ–º–∞–Ω–¥—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
@dp.message(Command("image"))
async def image_command(message: Message):
    prompt = message.text[len("/image"):].strip()

    if not prompt:
        await message.answer(
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏, —á—Ç–æ –Ω—É–∂–Ω–æ –Ω–∞—Ä–∏—Å–æ–≤–∞—Ç—å. \n"
            "–ü—Ä–∏–º–µ—Ä: `/image —Ä—ã–∂–∏–π –∫–æ—Ç –≤ —Å–∫–∞—Ñ–∞–Ω–¥—Ä–µ`", 
            parse_mode="Markdown"
        )
        return

    logging.info(f"User {message.from_user.id} requested an image generation.")
    
    await message.answer("üé® –°–æ–∑–¥–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã.")
    await message.chat.do("upload_photo")

    proxies = {"all://": PROXY_URL} if PROXY_URL else None
    start_time = time.time()

    try:
        async with httpx.AsyncClient(timeout=120.0, proxies=proxies) as client:
            response = await client.post(
                "https://api.openai.com/v1/images/generations",
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}"},
                json={
                    "model": "dall-e-3",
                    "prompt": prompt,
                    "n": 1,
                    "size": "1024x1024",
                    "quality": "standard"
                }
            )
            response.raise_for_status()
            data = response.json()
            image_url = data['data'][0]['url']
            
            duration = time.time() - start_time
            logging.info(f"SUCCESS image generation for user_id: {message.from_user.id}. Duration: {duration:.2f}s")

            await message.answer_photo(photo=image_url, caption=f"–í–∞—à–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –∑–∞–ø—Ä–æ—Å—É: ¬´{prompt}¬ª")

    except httpx.HTTPStatusError as http_err:
        duration = time.time() - start_time
        logging.error(f"HTTP ERROR during image generation for user_id: {message.from_user.id}. Status: {http_err.response.status_code}. Details: {http_err.response.text}. Duration: {duration:.2f}s")
        await message.answer(f"‚ùå *–û—à–∏–±–∫–∞ API ({http_err.response.status_code})* \n–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.", parse_mode="Markdown")
    except Exception as e:
        duration = time.time() - start_time
        logging.exception(f"SYSTEM ERROR during image generation for user_id: {message.from_user.id}. Duration: {duration:.2f}s. Error: {e}")
        await message.answer("‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")


# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–Ω–æ–ø–æ–∫ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
@dp.callback_query(lambda c: c.data.startswith("provider_"))
async def provider_selection(callback_query: types.CallbackQuery):
    provider = callback_query.data.split("_")[1]
    user_id = callback_query.from_user.id
    if user_id not in user_state:
        reset_user_state(user_id)
    user_state[user_id]["provider"] = provider
    buttons, text_parts, models_dict, header = [], [], {}, ""
    if provider == "openai": models_dict, header = openai_models, "üîπ *–í—ã–±—Ä–∞–Ω ChatGPT (OpenAI)*\n\n"
    elif provider == "grok": models_dict, header = grok_models, "üß† *–í—ã–±—Ä–∞–Ω Grok (xAI)*\n\n"
    elif provider == "gemini": models_dict, header = gemini_models, "‚ö° *–í—ã–±—Ä–∞–Ω Gemini (Google)*\n\n"
    text_parts.append(header + "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∏–∂–µ:")
    for name, data in models_dict.items():
        text_parts.append(f"\n\n*{name}*\n_{data['desc']}_")
        buttons.append([InlineKeyboardButton(text=name, callback_data=f"model_{data['id']}")])
    buttons.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_main")])
    await callback_query.message.edit_text("\n".join(text_parts), parse_mode="Markdown", reply_markup=InlineKeyboardMarkup(inline_keyboard=buttons))
@dp.callback_query(lambda c: c.data == "back_to_main")
async def back_to_main_menu(callback_query: types.CallbackQuery):
    reset_user_state(callback_query.from_user.id)
    await callback_query.message.edit_text("üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç *NeuroZone*...", parse_mode="Markdown", reply_markup=main_menu())
@dp.callback_query(lambda c: c.data.startswith("model_"))
async def model_selection(callback_query: types.CallbackQuery):
    model_id = callback_query.data.split("_", 1)[1]
    user_id = callback_query.from_user.id
    if user_id not in user_state or not user_state[user_id].get("provider"): await callback_query.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.", show_alert=True); return
    user_state[user_id]["model"] = model_id
    provider = user_state[user_id]['provider'].capitalize()
    await callback_query.message.edit_text(f"‚úÖ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: *{provider}*\n‚úÖ –ú–æ–¥–µ–ª—å: *{model_id}*\n\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å.", parse_mode="Markdown")


# –ò–ó–ú–ï–ù–ï–ù–û: –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π —Å —ç—Ç–∏—á–Ω—ã–º –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º
@dp.message()
async def handle_message(message: Message):
    user_id = message.from_user.id
    if user_id not in user_state or not user_state[user_id].get("model"):
        await message.answer("‚öôÔ∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ /start –∏–ª–∏ /reset")
        return

    logging.info(f"Received message from user_id: {user_id}")
    start_time = time.time()

    provider = user_state[user_id]["provider"]
    model = user_state[user_id]["model"]
    user_input = message.text.strip()
    history = user_state[user_id].get("history", [])

    if len(history) > MAX_HISTORY_LENGTH:
        history = history[-MAX_HISTORY_LENGTH:]

    await message.chat.do("typing")
    
    answer = ""
    proxies = {"all://": PROXY_URL} if PROXY_URL else None
    
    try:
        async with httpx.AsyncClient(timeout=90.0, proxies=proxies) as client:
            if provider == "openai" or provider == "grok":
                history.append({"role": "user", "content": user_input})
                api_url = "https://api.openai.com/v1/chat/completions" if provider == "openai" else f"{GROK_API_BASE}/chat/completions"
                api_key = OPENAI_API_KEY if provider == "openai" else GROK_API_KEY
                response = await client.post(api_url, headers={"Authorization": f"Bearer {api_key}"}, json={"model": model, "messages": history})
                response.raise_for_status()
                data = response.json()
                answer = data["choices"][0]["message"]["content"]
                history.append({"role": "assistant", "content": answer})
            elif provider == "gemini":
                gemini_history = [{"role": "user" if msg["role"] == "user" else "model", "parts": [{"text": msg["content"]}]} for msg in history]
                gemini_history.append({"role": "user", "parts": [{"text": user_input}]})
                gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_API_KEY}"
                response = await client.post(gemini_url, headers={"Content-Type": "application/json"}, json={"contents": gemini_history})
                response.raise_for_status()
                data = response.json()
                answer = data.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Ç–≤–µ—Ç.")
                history.append({"role": "user", "content": user_input})
                history.append({"role": "assistant", "content": answer})

            duration = time.time() - start_time
            logging.info(f"SUCCESS for user_id: {user_id}. Provider: {provider}, Model: {model}. Duration: {duration:.2f}s")

    except httpx.HTTPStatusError as http_err:
        duration = time.time() - start_time
        logging.error(f"HTTP ERROR for user_id: {user_id}. Provider: {provider}, Model: {model}. Status: {http_err.response.status_code}. Details: {http_err.response.text}. Duration: {duration:.2f}s")
        answer = f"‚ùå *–û—à–∏–±–∫–∞ API ({http_err.response.status_code})*"
    except Exception as e:
        duration = time.time() - start_time
        logging.exception(f"SYSTEM ERROR for user_id: {user_id}. Provider: {provider}, Model: {model}. Duration: {duration:.2f}s. Error: {e}")
        answer = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞."

    user_state[user_id]["history"] = history
    await message.answer(answer, parse_mode="Markdown")


# === –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ===
async def main():
    if not TELEGRAM_TOKEN: 
        logging.error("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        return
    logging.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
