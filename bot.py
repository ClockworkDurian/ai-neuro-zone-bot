import os
import sys
import logging
import asyncio
import httpx
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, Message
from dotenv import load_dotenv

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –¥–ª—è Windows ===
sys.stdout.reconfigure(encoding='utf-8')

# === –õ–æ–≥–∏ ===
logging.basicConfig(level=logging.INFO)

# === –ó–∞–≥—Ä—É–∑–∫–∞ .env ===
load_dotenv()

TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN") or os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROK_API_KEY = os.getenv("GROK_API_KEY") or os.getenv("XAI_API_KEY")
GROK_API_BASE = os.getenv("GROK_API_BASE", "https://api.x.ai/v1")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PROXY_URL = os.getenv("PROXY_URL")

bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()

# === –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∏—Å—Ç–æ—Ä–∏—è ===
user_state = {}

# –ò–ó–ú–ï–ù–ï–ù–û: –ö–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –¥–ª—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏ (10 —Ä–µ–ø–ª–∏–∫ = 5 –ø–∞—Ä –≤–æ–ø—Ä–æ—Å-–æ—Ç–≤–µ—Ç)
MAX_HISTORY_LENGTH = 10

# === –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é –∏ –ú–æ–¥–µ–ª–∏ ===
# (–≠—Ç–æ—Ç –±–ª–æ–∫ –∫–æ–¥–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è, –ø–æ—ç—Ç–æ–º—É –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏ —è –µ–≥–æ —Å–∫—Ä–æ—é)
def main_menu():
    buttons = [
        [InlineKeyboardButton(text="üí≠ ChatGPT (OpenAI)", callback_data="provider_openai")],
        [InlineKeyboardButton(text="üß† Grok (xAI)", callback_data="provider_grok")],
        [InlineKeyboardButton(text="‚ö° Gemini (Google)", callback_data="provider_gemini")],
        [InlineKeyboardButton(text="üåê –°–∞–π—Ç", url="https://neurozone.pro/")],
        [InlineKeyboardButton(text="üîí –ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏", url="https://neurozone.pro/privacy")],
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
openai_models = { "GPT-5": {"id": "gpt-5", "desc": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å..."}, "GPT-5 mini": {"id": "gpt-5-mini", "desc": "–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è..."}, "GPT-5 nano": {"id": "gpt-5-nano", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è..."}, "GPT-4.1": {"id": "gpt-4.1", "desc": "–°–∞–º–∞—è —É–º–Ω–∞—è..."}}
grok_models = {"Grok-code-fast-1": {"id": "grok-code-fast-1", "desc": "–ë—ã—Å—Ç—Ä–∞—è..."}, "Grok-4-fast-reasoning": {"id": "grok-4-fast-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ..."}, "Grok-4-fast-non-reasoning": {"id": "grok-4-fast-non-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ..."}}
gemini_models = {"Gemini 2.5 Flash": {"id": "gemini-2.5-flash", "desc": "–õ—É—á—à–∞—è..."},"Gemini 2.5 Flash-Lite": {"id": "gemini-2.5-flash-lite", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è..."}}
# === –ö–æ–Ω–µ—Ü —Å–∫—Ä—ã—Ç–æ–≥–æ –±–ª–æ–∫–∞ ===


# –ò–ó–ú–ï–ù–ï–ù–û: –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–±—Ä–æ—Å–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –∏—Å—Ç–æ—Ä–∏–∏
def reset_user_state(user_id):
    user_state[user_id] = {"provider": None, "model": None, "history": []}


# === /start ===
@dp.message(Command("start"))
async def start_command(message: Message):
    reset_user_state(message.from_user.id) # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    await message.answer(
        "üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç *NeuroZone*.\n\n"
        "–Ø –∑–∞–ø–æ–º–∏–Ω–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞—à–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞. –ß—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥, –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—É /reset.\n\n"
        "–í—ã–±–µ—Ä–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å, —Å –∫–æ—Ç–æ—Ä–æ–π —Ö–æ—á–µ—à—å —Ä–∞–±–æ—Ç–∞—Ç—å:",
        parse_mode="Markdown",
        reply_markup=main_menu()
    )

# –ò–ó–ú–ï–ù–ï–ù–û: –ù–æ–≤–∞—è –∫–æ–º–∞–Ω–¥–∞ /reset –¥–ª—è —Å–±—Ä–æ—Å–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
@dp.message(Command("reset"))
async def reset_command(message: Message):
    reset_user_state(message.from_user.id)
    await message.answer(
        "‚úÖ –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ —Å–±—Ä–æ—à–µ–Ω. –ù–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π –¥–∏–∞–ª–æ–≥!\n\n–í—ã–±–µ—Ä–∏ –Ω–µ–π—Ä–æ—Å–µ—Ç—å:",
        parse_mode="Markdown",
        reply_markup=main_menu()
    )


# === –í—ã–±–æ—Ä –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ ===
@dp.callback_query(lambda c: c.data.startswith("provider_"))
async def provider_selection(callback_query: types.CallbackQuery):
    provider = callback_query.data.split("_")[1]
    user_id = callback_query.from_user.id
    # –ò–ó–ú–ï–ù–ï–ù–û: –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –∏—Å—Ç–æ—Ä–∏—è —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
    if user_id not in user_state:
        reset_user_state(user_id)
    user_state[user_id]["provider"] = provider
    
    # ... –æ—Å—Ç–∞–ª—å–Ω–æ–π –∫–æ–¥ –≤—ã–±–æ—Ä–∞ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–µ –∏–∑–º–µ–Ω–∏–ª—Å—è ...
    buttons, text_parts, models_dict, header = [], [], {}, ""
    if provider == "openai": models_dict, header = openai_models, "üîπ *–í—ã–±—Ä–∞–Ω ChatGPT (OpenAI)*\n\n"
    elif provider == "grok": models_dict, header = grok_models, "üß† *–í—ã–±—Ä–∞–Ω Grok (xAI)*\n\n"
    elif provider == "gemini": models_dict, header = gemini_models, "‚ö° *–í—ã–±—Ä–∞–Ω Gemini (Google)*\n\n"
    text_parts.append(header + "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∏–∂–µ:")
    for name, data in models_dict.items():
        text_parts.append(f"\n\n*{name}*\n_{data['desc']}_")
        buttons.append([InlineKeyboardButton(text=name, callback_data=f"model_{data['id']}")])
    buttons.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back_to_main")])
    await callback_query.message.edit_text("\n".join(text_parts), parse_mode="Markdown", reply_markup=InlineKeyboardMarkup(inline_keyboard=buttons))


# ... –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ back_to_main –∏ model_selection –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∏—Å—å ...
@dp.callback_query(lambda c: c.data == "back_to_main")
async def back_to_main_menu(callback_query: types.CallbackQuery):
    reset_user_state(callback_query.from_user.id)
    await callback_query.message.edit_text("üëã –ü—Ä–∏–≤–µ—Ç! ...", parse_mode="Markdown", reply_markup=main_menu())
@dp.callback_query(lambda c: c.data.startswith("model_"))
async def model_selection(callback_query: types.CallbackQuery):
    model_id = callback_query.data.split("_", 1)[1]
    user_id = callback_query.from_user.id
    if user_id not in user_state or not user_state[user_id].get("provider"): await callback_query.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.", show_alert=True); return
    user_state[user_id]["model"] = model_id
    provider = user_state[user_id]['provider'].capitalize()
    await callback_query.message.edit_text(f"‚úÖ –ü—Ä–æ–≤–∞–π–¥–µ—Ä: *{provider}*\n‚úÖ –ú–æ–¥–µ–ª—å: *{model_id}*\n\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å.", parse_mode="Markdown")


# === –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π (–ö–õ–Æ–ß–ï–í–´–ï –ò–ó–ú–ï–ù–ï–ù–ò–Ø) ===
@dp.message()
async def handle_message(message: Message):
    user_id = message.from_user.id
    if user_id not in user_state or not user_state[user_id].get("model"):
        await message.answer("‚öôÔ∏è –°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏ –º–æ–¥–µ–ª—å —á–µ—Ä–µ–∑ /start –∏–ª–∏ /reset")
        return

    provider = user_state[user_id]["provider"]
    model = user_state[user_id]["model"]
    user_input = message.text.strip()
    
    # –ò–ó–ú–ï–ù–ï–ù–û: –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    history = user_state[user_id].get("history", [])

    # –ò–ó–ú–ï–ù–ï–ù–û: –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É –∏—Å—Ç–æ—Ä–∏–∏, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è
    if len(history) > MAX_HISTORY_LENGTH:
        history = history[-MAX_HISTORY_LENGTH:]

    await message.chat.do("typing")
    
    answer = ""
    proxies = {"all://": PROXY_URL} if PROXY_URL else None
    
    try:
        async with httpx.AsyncClient(timeout=90.0, proxies=proxies) as client:
            if provider == "openai" or provider == "grok":
                # –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å –≤ –∏—Å—Ç–æ—Ä–∏—é
                history.append({"role": "user", "content": user_input})
                
                api_url = "https://api.openai.com/v1/chat/completions" if provider == "openai" else f"{GROK_API_BASE}/chat/completions"
                api_key = OPENAI_API_KEY if provider == "openai" else GROK_API_KEY
                
                response = await client.post(
                    api_url,
                    headers={"Authorization": f"Bearer {api_key}"},
                    # –ò–ó–ú–ï–ù–ï–ù–û: –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é
                    json={"model": model, "messages": history}
                )
                response.raise_for_status()
                data = response.json()
                answer = data["choices"][0]["message"]["content"]
                # –ò–ó–ú–ï–ù–ï–ù–û: –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ –≤ –∏—Å—Ç–æ—Ä–∏—é
                history.append({"role": "assistant", "content": answer})

            elif provider == "gemini":
                # Gemini –∏–º–µ–µ—Ç –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç –∏—Å—Ç–æ—Ä–∏–∏, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ
                gemini_history = []
                for msg in history:
                    role = "user" if msg["role"] == "user" else "model"
                    gemini_history.append({"role": role, "parts": [{"text": msg["content"]}]})
                
                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–∏–π –≤–æ–ø—Ä–æ—Å
                gemini_history.append({"role": "user", "parts": [{"text": user_input}]})

                gemini_url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={GEMINI_API_KEY}"
                response = await client.post(
                    gemini_url,
                    headers={"Content-Type": "application/json"},
                    json={"contents": gemini_history} # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
                )
                response.raise_for_status()
                data = response.json()
                answer = data.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –æ—Ç–≤–µ—Ç.")
                
                # –ò–ó–ú–ï–ù–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –≤ –Ω–∞—à–µ–º —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
                history.append({"role": "user", "content": user_input})
                history.append({"role": "assistant", "content": answer})

            else:
                answer = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä."
    
    # ... –±–ª–æ–∫ except –æ—Å—Ç–∞–ª—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π ...
    except httpx.HTTPStatusError as http_err: logging.error(f"–û—à–∏–±–∫–∞ HTTP: {http_err.response.status_code} - {http_err.response.text}"); answer = f"‚ùå *–û—à–∏–±–∫–∞ API ({http_err.response.status_code})*"
    except Exception as e: logging.exception("–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞"); answer = f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {str(e)}"

    # –ò–ó–ú–ï–ù–ï–ù–û: –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—É—é –∏—Å—Ç–æ—Ä–∏—é
    user_state[user_id]["history"] = history
    
    await message.answer(answer, parse_mode="Markdown")


# === –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ===
async def main():
    if not TELEGRAM_TOKEN: logging.error("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!"); return
    logging.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
