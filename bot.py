import os
import sys
import logging
import asyncio
import time
import openai
import google.generativeai as genai
from xai_sdk import Client as XAI_Client
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, Message
from dotenv import load_dotenv

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ –∏ –ª–æ–≥–æ–≤ ===
sys.stdout.reconfigure(encoding='utf-8')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# === –ó–∞–≥—Ä—É–∑–∫–∞ .env –∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ API ===
load_dotenv()
TELEGRAM_TOKEN = os.getenv("TELEGRAM_TOKEN") or os.getenv("BOT_TOKEN")
openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
xai_client = XAI_Client(api_key=os.getenv("GROK_API_KEY"))
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

bot = Bot(token=TELEGRAM_TOKEN)
dp = Dispatcher()

# === –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π, –∏—Å—Ç–æ—Ä–∏—è, –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
user_state = {}
MAX_HISTORY_LENGTH = 10

# === –ú–æ–¥–µ–ª–∏ —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏ ===
openai_models = { "GPT-5": {"id": "gpt-5", "desc": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞ –∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."}, "GPT-5 mini": {"id": "gpt-5-mini", "desc": "–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."}, "GPT-5 nano": {"id": "gpt-5-nano", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."}, "GPT-4.1": {"id": "gpt-4.1", "desc": "–°–∞–º–∞—è —É–º–Ω–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π."}}
grok_models = {"Grok-code-fast-1": {"id": "grok-code-fast-1", "desc": "–ë—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è."}, "Grok-4-fast-reasoning": {"id": "grok-4-fast-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."}, "Grok-4-fast-non-reasoning": {"id": "grok-4-fast-non-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."}}
gemini_models = {"Gemini 2.5 Flash": {"id": "gemini-2.5-flash", "desc": "–õ—É—á—à–∞—è –ø–æ —Ü–µ–Ω–µ/–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."}, "Gemini 2.5 Flash-Lite": {"id": "gemini-2.5-flash-lite", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è flash-–º–æ–¥–µ–ª—å."}}

# === –ë–ª–æ–∫ —Å –º–µ–Ω—é ===
def main_mode_menu():
    buttons = [[InlineKeyboardButton(text="‚úçÔ∏è –¢–µ–∫—Å—Ç–æ–≤—ã–π —á–∞—Ç", callback_data="mode_textchat")], [InlineKeyboardButton(text="üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="mode_imagegen")], [InlineKeyboardButton(text="üåê –°–∞–π—Ç", url="https://neurozone.pro/")], [InlineKeyboardButton(text="üîí –ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏", url="https://neurozone.pro/privacy")]]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
def text_provider_menu():
    buttons = [[InlineKeyboardButton(text="üí≠ ChatGPT (OpenAI)", callback_data="provider_openai")], [InlineKeyboardButton(text="üß† Grok (xAI)", callback_data="provider_grok")], [InlineKeyboardButton(text="‚ö° Gemini (Google)", callback_data="provider_gemini")], [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main_menu")]]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
def image_provider_menu():
    buttons = [[InlineKeyboardButton(text=" DALL-E 3 (OpenAI)", callback_data="image_provider_openai")], [InlineKeyboardButton(text=" Grok Image (xAI)", callback_data="image_provider_grok")], [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main_menu")]]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
def reset_user_state(user_id):
    user_state[user_id] = {"provider": None, "model": None, "history": [], "mode": None}

# === –ö–æ–º–∞–Ω–¥—ã –∏ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–Ω–æ–ø–æ–∫ ===
@dp.message(Command("start", "reset"))
async def start_reset_command(message: Message): reset_user_state(message.from_user.id); await message.answer("üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç *NeuroZone*.\n\n–í—ã–±–µ—Ä–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å:", parse_mode="Markdown", reply_markup=main_mode_menu())
@dp.callback_query(lambda c: c.data == "back_to_main_menu")
async def back_to_main_menu_handler(callback_query: types.CallbackQuery): reset_user_state(callback_query.from_user.id); await callback_query.message.edit_text("üëã –ü—Ä–∏–≤–µ—Ç! ...", parse_mode="Markdown", reply_markup=main_mode_menu())
@dp.callback_query(lambda c: c.data.startswith("mode_"))
async def mode_selection_handler(callback_query: types.CallbackQuery):
    mode = callback_query.data.split("_")[1]; user_id = callback_query.from_user.id
    if user_id not in user_state: reset_user_state(user_id)
    user_state[user_id]["mode"] = mode
    if mode == "textchat": await callback_query.message.edit_text("–í—ã–±—Ä–∞–Ω —Ä–µ–∂–∏–º —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞. –í—ã–±–µ—Ä–∏—Ç–µ –Ω–µ–π—Ä–æ—Å–µ—Ç—å:", reply_markup=text_provider_menu())
    elif mode == "imagegen": await callback_query.message.edit_text("–í—ã–±—Ä–∞–Ω —Ä–µ–∂–∏–º –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π. –í—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é:", reply_markup=image_provider_menu())
@dp.callback_query(lambda c: c.data.startswith("provider_"))
async def text_provider_selection(callback_query: types.CallbackQuery):
    provider = callback_query.data.split("_")[1]; user_id = callback_query.from_user.id; user_state[user_id]["provider"] = provider; models_dict, header = {}, ""
    if provider == "openai": models_dict, header = openai_models, "üîπ *ChatGPT (OpenAI)*"
    elif provider == "grok": models_dict, header = grok_models, "üß† *Grok (xAI)*"
    elif provider == "gemini": models_dict, header = gemini_models, "‚ö° *Gemini (Google)*"
    text_parts = [f"{header}\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:"]; buttons = []
    for name, data in models_dict.items(): text_parts.append(f"\n*{name}* - _{data['desc']}_"); buttons.append([InlineKeyboardButton(text=name, callback_data=f"model_{data['id']}")])
    buttons.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="mode_textchat")]); await callback_query.message.edit_text("\n".join(text_parts), parse_mode="Markdown", reply_markup=InlineKeyboardMarkup(inline_keyboard=buttons))
@dp.callback_query(lambda c: c.data.startswith("model_"))
async def model_selection(callback_query: types.CallbackQuery):
    model_id = callback_query.data.split("_", 1)[1]; user_id = callback_query.from_user.id
    if user_id not in user_state or not user_state[user_id].get("provider"): await callback_query.answer("–û—à–∏–±–∫–∞. –ù–∞—á–Ω–∏—Ç–µ —Å /start"); return
    user_state[user_id]["model"] = model_id; await callback_query.message.edit_text(f"‚úÖ –ú–æ–¥–µ–ª—å *{model_id}* –≤—ã–±—Ä–∞–Ω–∞.\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å.", parse_mode="Markdown")
@dp.callback_query(lambda c: c.data.startswith("image_provider_"))
async def image_provider_selection(callback_query: types.CallbackQuery):
    provider = callback_query.data.split("_")[2]; user_id = callback_query.from_user.id
    if user_id not in user_state: reset_user_state(user_id)
    user_state[user_id]["provider"] = provider; provider_name = ""
    if provider == "openai": provider_name = "DALL-E 3 (OpenAI)"
    elif provider == "grok": provider_name = "Grok Image (xAI)"
    await callback_query.message.edit_text(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è: *{provider_name}*.\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.", parse_mode="Markdown")

# --- –ì–õ–ê–í–ù–´–ô –û–ë–†–ê–ë–û–¢–ß–ò–ö –°–û–û–ë–©–ï–ù–ò–ô ---
@dp.message()
async def main_message_handler(message: Message):
    user_id = message.from_user.id
    if user_id not in user_state or not user_state[user_id].get("mode"): await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —á–µ—Ä–µ–∑ /start"); return
    mode = user_state[user_id]["mode"]
    if mode == "textchat": await handle_text_chat(message)
    elif mode == "imagegen": await handle_image_generation(message)
    else: await message.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º. –ù–∞—á–Ω–∏—Ç–µ —Å /start")

# –õ–æ–≥–∏–∫–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞
async def handle_text_chat(message: Message):
    user_id = message.from_user.id
    if not user_state[user_id].get("model"):
        await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å.")
        return

    logging.info(f"Received text message from user_id: {user_id}")
    start_time = time.time()
    provider = user_state[user_id]["provider"]
    model_id = user_state[user_id]["model"]
    user_input = message.text.strip()
    history = user_state[user_id].get("history", [])
    if len(history) > MAX_HISTORY_LENGTH: history = history[-MAX_HISTORY_LENGTH:]

    await message.chat.do("typing")
    answer = ""
    
    try:
        if provider == "openai":
            history.append({"role": "user", "content": user_input})
            response = await openai_client.chat.completions.create(model=model_id, messages=history)
            answer = response.choices[0].message.content
            history.append({"role": "assistant", "content": answer})

        elif provider == "grok":
            # –ò–°–ü–†–ê–í–õ–ï–ù–û: –°–∏–Ω—Ç–∞–∫—Å–∏—Å —Ä–∞–∑–¥–µ–ª–µ–Ω –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫
            history.append({"role": "user", "content": user_input})
            def _generate_grok_chat():
                chat_completion = xai_client.chat.create(model=model_id, messages=history)
                return chat_completion.choices[0].message.content
            answer = await asyncio.to_thread(_generate_grok_chat)
            history.append({"role": "assistant", "content": answer})
            
        elif provider == "gemini":
            gemini_model = genai.GenerativeModel(model_id)
            gemini_sdk_history = [{"role": "user" if msg["role"] == "user" else "model", "parts": [msg["content"]]} for msg in history]
            chat_session = gemini_model.start_chat(history=gemini_sdk_history)
            response = await chat_session.send_message_async(user_input)
            answer = response.text
            history.append({"role": "user", "content": user_input})
            history.append({"role": "assistant", "content": answer})

        duration = time.time() - start_time
        logging.info(f"SUCCESS text chat for user_id: {user_id}. Provider: {provider}, Model: {model_id}. Duration: {duration:.2f}s")
    
    except Exception as e:
        duration = time.time() - start_time
        logging.exception(f"ERROR during text chat for user_id: {user_id}. Provider: {provider}. Error: {e}")
        answer = f"‚ùå *–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.*\n\n_{str(e)}_."

    user_state[user_id]["history"] = history
    await message.answer(answer, parse_mode="Markdown")

# –õ–æ–≥–∏–∫–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
async def handle_image_generation(message: Message):
    user_id = message.from_user.id; provider = user_state[user_id].get("provider")
    if not provider: await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."); return
    prompt = message.text.strip(); logging.info(f"User {user_id} requested an image with provider '{provider}'."); await message.answer("üé® –°–æ–∑–¥–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –¥–æ –º–∏–Ω—É—Ç—ã."); await message.chat.do("upload_photo")
    start_time = time.time()
    try:
        image_url, caption = "", ""
        if provider == "openai":
            response = await openai_client.images.generate(model="dall-e-3", prompt=prompt, n=1, size="1024x1024"); image_url = response.data[0].url; caption = f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç DALL-E 3:\n¬´{prompt}¬ª"
        elif provider == "grok":
            def _generate_grok_image(): response = xai_client.image.sample(model="grok-2-image-1212", prompt=prompt, image_format="url"); return response.url
            image_url = await asyncio.to_thread(_generate_grok_image); caption = f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç Grok Image:\n¬´{prompt}¬ª"
        if image_url:
            duration = time.time() - start_time; logging.info(f"SUCCESS image generation for user_id: {user_id}. Provider: {provider}. Duration: {duration:.2f}s"); await message.answer_photo(photo=image_url, caption=caption)
        else: raise Exception("Provider logic is not implemented")
    except Exception as e:
        duration = time.time() - start_time; logging.exception(f"ERROR during image generation for user_id: {user_id}. Provider: {provider}")
        error_text = str(e) if str(e) else "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞."; await message.answer(f"‚ùå *–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.*\n\n_{error_text}_", parse_mode="Markdown")

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ ===
async def main():
    if not TELEGRAM_TOKEN: logging.error("–¢–æ–∫–µ–Ω –±–æ—Ç–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω!"); return
    await bot.delete_webhook(drop_pending_updates=True)
    logging.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    await bot.set_my_commands([types.BotCommand(command="start", description="–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞ –∏ –≤—ã–±—Ä–∞—Ç—å —Ä–µ–∂–∏–º"), types.BotCommand(command="reset", description="–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞ –∏ –≤—ã–±—Ä–∞—Ç—å —Ä–µ–∂–∏–º")])
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
