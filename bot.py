# bot.py ‚Äî –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º —Å –Ω–æ–≤—ã–º llm_core.py (OpenAI + Grok + Gemini)
# aiogram 3.13.1

import asyncio
import logging
import os
import time
from collections import defaultdict, deque

from aiogram import Bot, Dispatcher, types
from aiogram.client.default import DefaultBotProperties
from aiogram.filters import Command
from aiogram.exceptions import TelegramAPIError
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup

from llm_core import (
    generate_text_stream,
    generate_text,
    generate_image,
    trim_history_by_tokens
)

# -------------------------------------------------------------------
# –õ–û–ì–ò
# -------------------------------------------------------------------

logger = logging.getLogger("neurozone_bot")
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
logger.addHandler(handler)

def safe_log(uid, event, extra=None):
    d = {"user_id": uid, "event": event}
    if extra:
        d.update(extra)
    logger.info(d)

# -------------------------------------------------------------------
# ENV VARS
# -------------------------------------------------------------------

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROK_API_KEY = os.getenv("GROK_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not BOT_TOKEN:
    raise SystemExit("‚ùå BOT_TOKEN –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")

# -------------------------------------------------------------------
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø AIROGRAM
# -------------------------------------------------------------------

bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode="HTML"))
dp = Dispatcher()

# -------------------------------------------------------------------
# RATE LIMIT
# -------------------------------------------------------------------

RATE_LIMIT_PER_MINUTE = 30
user_requests = defaultdict(lambda: deque())

def check_rate_limit(uid: int) -> bool:
    now = time.time()
    dq = user_requests[uid]
    while dq and dq[0] < now - 60:
        dq.popleft()
    if len(dq) >= RATE_LIMIT_PER_MINUTE:
        return False
    dq.append(now)
    return True

# -------------------------------------------------------------------
# –°–û–°–¢–û–Ø–ù–ò–ï –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–ï–ô
# -------------------------------------------------------------------

MAX_HISTORY_TOKENS_DEFAULT = 3000

user_state = defaultdict(lambda: {
    "mode": None,
    "provider": None,
    "model": None,
    "history": [],
    "max_history_tokens": MAX_HISTORY_TOKENS_DEFAULT
})

# -------------------------------------------------------------------
# –ú–û–î–ï–õ–ò (–ö–ê–ö –í –°–¢–ê–†–û–ú –ë–û–¢–ï)
# -------------------------------------------------------------------

openai_models = {
    "GPT-5": {"id": "gpt-5", "desc": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞ –∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."},
    "GPT-5 mini": {"id": "gpt-5-mini", "desc": "–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."},
    "GPT-5 nano": {"id": "gpt-5-nano", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."},
    "GPT-4.1": {"id": "gpt-4.1", "desc": "–°–∞–º–∞—è —É–º–Ω–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π."}
}

grok_models = {
    "Grok-code-fast-1": {"id": "grok-code-fast-1", "desc": "–ë—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è."},
    "Grok-4-fast-reasoning": {"id": "grok-4-fast-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."},
    "Grok-4-fast-non-reasoning": {"id": "grok-4-fast-non-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."}
}

gemini_models = {
    "Gemini 2.5 Flash": {"id": "gemini-2.5-flash", "desc": "–õ—É—á—à–∞—è –ø–æ —Ü–µ–Ω–µ/–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."},
    "Gemini 2.5 Flash-Lite": {"id": "gemini-2.5-flash-lite", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è flash-–º–æ–¥–µ–ª—å."}
}

# -------------------------------------------------------------------
# –ö–õ–ê–í–ò–ê–¢–£–†–´
# -------------------------------------------------------------------

def kb_main():
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="–¢–µ–∫—Å—Ç", callback_data="mode:text"),
            InlineKeyboardButton(text="–ö–∞—Ä—Ç–∏–Ω–∫–∏", callback_data="mode:image")
        ],
        [
            InlineKeyboardButton(text="OpenAI", callback_data="provider:openai"),
            InlineKeyboardButton(text="Grok", callback_data="provider:grok"),
            InlineKeyboardButton(text="Gemini", callback_data="provider:gemini")
        ],
        [
            InlineKeyboardButton(text="–°–±—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏", callback_data="reset:history")
        ]
    ])

def menu_after_answer():
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back:main")]
    ])

def model_selected_menu():
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º", callback_data="back:providers")],
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back:main")]
    ])

async def repost_menu(chat_id: int):
    try:
        await bot.send_message(chat_id, "–ú–µ–Ω—é:", reply_markup=kb_main())
    except Exception:
        pass

# -------------------------------------------------------------------
# –ü–û–ö–ê–ó –ú–û–î–ï–õ–ï–ô
# -------------------------------------------------------------------

async def show_models_for_provider(cb: types.CallbackQuery, provider_key: str):
    if provider_key == "openai":
        models = openai_models
        header = "üîµ <b>OpenAI ‚Äî ChatGPT –º–æ–¥–µ–ª–∏</b>"
    elif provider_key == "grok":
        models = grok_models
        header = "üß† <b>Grok ‚Äî xAI –º–æ–¥–µ–ª–∏</b>"
    else:
        models = gemini_models
        header = "‚ö° <b>Gemini ‚Äî Google AI –º–æ–¥–µ–ª–∏</b>"

    txt = [f"{header}\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:"]
    kb = []

    for name, meta in models.items():
        txt.append(f"\n<b>{name}</b> ‚Äî <i>{meta['desc']}</i>")
        kb.append([InlineKeyboardButton(text=name, callback_data=f"model:{meta['id']}")])

    kb.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back:providers")])

    msg = "\n".join(txt)

    try:
        await cb.message.edit_text(msg, reply_markup=InlineKeyboardMarkup(inline_keyboard=kb))
    except:
        await cb.message.answer(msg, reply_markup=InlineKeyboardMarkup(inline_keyboard=kb))

    await cb.answer()

# -------------------------------------------------------------------
# CALLBACK HANDLERS
# -------------------------------------------------------------------

@dp.message(Command("start", "help"))
async def start_cmd(message: types.Message):
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:", reply_markup=kb_main())

@dp.callback_query(lambda c: c.data and c.data.startswith("mode:"))
async def choose_mode(cb: types.CallbackQuery):
    uid = cb.from_user.id
    mode = cb.data.split(":", 1)[1]
    user_state[uid]["mode"] = mode
    safe_log(uid, "mode_set", {"mode": mode})
    await cb.message.edit_text(f"–†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: <b>{mode}</b>\n–¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:", reply_markup=kb_main())
    await cb.answer()

@dp.callback_query(lambda c: c.data and c.data.startswith("provider:"))
async def choose_provider(cb: types.CallbackQuery):
    uid = cb.from_user.id
    prov = cb.data.split(":", 1)[1]
    user_state[uid]["provider"] = prov
    safe_log(uid, "provider_set", {"provider": prov})
    await show_models_for_provider(cb, prov)

@dp.callback_query(lambda c: c.data == "back:providers")
async def back_to_providers(cb: types.CallbackQuery):
    await cb.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:", reply_markup=kb_main())
    await cb.answer()

@dp.callback_query(lambda c: c.data and c.data.startswith("model:"))
async def choose_model(cb: types.CallbackQuery):
    uid = cb.from_user.id
    model = cb.data.split(":", 1)[1]
    user_state[uid]["model"] = model
    safe_log(uid, "model_set", {"model": model})
    await cb.message.edit_text(
        f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å:\n<b>{model}</b>\n\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.",
        reply_markup=model_selected_menu()
    )
    await cb.answer()

@dp.callback_query(lambda c: c.data == "reset:history")
async def reset_history(cb: types.CallbackQuery):
    uid = cb.from_user.id
    user_state[uid]["history"] = []
    safe_log(uid, "history_reset")
    await cb.message.edit_text("–ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞.", reply_markup=kb_main())
    await cb.answer()

@dp.callback_query(lambda c: c.data == "back:main")
async def back_main(cb: types.CallbackQuery):
    await cb.message.edit_text("–ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é:", reply_markup=kb_main())
    await cb.answer()

# -------------------------------------------------------------------
# MESSAGE HANDLER
# -------------------------------------------------------------------

@dp.message()
async def on_message(message: types.Message):
    uid = message.from_user.id
    text = message.text or ""
    safe_log(uid, "text_received", {"len": len(text)})

    if not check_rate_limit(uid):
        await message.answer("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –º–∏–Ω—É—Ç—É.")
        return

    st = user_state[uid]
    mode = st["mode"]
    provider = st["provider"]
    model = st["model"]

    if not mode:
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —á–µ—Ä–µ–∑ /start")
        return
    if not provider:
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞.")
        return
    if not model:
        await message.answer("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å.")
        return

    # ----------------------------------------
    # IMAGE MODE
    # ----------------------------------------
    if mode == "image":
        await message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
        try:
            url = await generate_image(
                provider=provider,
                prompt=text,
                openai_key=OPENAI_API_KEY,
                grok_key=GROK_API_KEY,
                gemini_key=GEMINI_API_KEY
            )
            await message.answer_photo(url, caption="–ì–æ—Ç–æ–≤–æ!")
        except Exception as e:
            safe_log(uid, "image_error", {"err": str(e)})
            await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        await repost_menu(message.chat.id)
        return

    # ----------------------------------------
    # TEXT MODE (STREAMING)
    # ----------------------------------------

    st["history"].append({"role": "user", "content": text})
    st["history"] = trim_history_by_tokens(st["history"], st["max_history_tokens"])

    status = await message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

    try:
        full = ""
        last_edit = time.time()

        stream = generate_text_stream(
            provider=provider,
            model=model,
            history=st["history"],
            user_input=text,
            openai_key=OPENAI_API_KEY,
            grok_key=GROK_API_KEY,
            gemini_key=GEMINI_API_KEY,
            max_history_tokens=st["max_history_tokens"]
        )

        async for chunk in stream:
            full += chunk
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞–∑ –≤ 0.35 —Å–µ–∫—É–Ω–¥—ã
            if time.time() - last_edit > 0.35:
                try:
                    await status.edit_text(full)
                except TelegramAPIError:
                    pass
                last_edit = time.time()

        try:
            await status.edit_text(full)
        except TelegramAPIError:
            pass

        st["history"].append({"role": "assistant", "content": full})
        st["history"] = trim_history_by_tokens(st["history"], st["max_history_tokens"])

    except Exception as e:
        safe_log(uid, "stream_error", {"err": str(e)})
        try:
            fallback = await generate_text(
                provider=provider,
                model=model,
                history=st["history"],
                user_input=text,
                openai_key=OPENAI_API_KEY,
                grok_key=GROK_API_KEY,
                gemini_key=GEMINI_API_KEY,
                max_history_tokens=st["max_history_tokens"]
            )
            await status.edit_text(fallback)
            st["history"].append({"role":"assistant", "content": fallback})
        except Exception as e2:
            safe_log(uid, "fallback_failed", {"err": str(e2)})
            await status.edit_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏.")

    await repost_menu(message.chat.id)

# -------------------------------------------------------------------
# MAIN
# -------------------------------------------------------------------

async def main():
    logger.info("Bot started")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
