# bot.py ‚Äî —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è (aiogram 3.13.1 + streaming + token limit + rate-limit + –º–æ–¥–µ–ª–∏ –∏–∑ —Å—Ç–∞—Ä–æ–≥–æ –±–æ—Ç–∞)

import asyncio
import logging
import os
import time
from collections import defaultdict, deque

from aiogram import Bot, Dispatcher, types
from aiogram.exceptions import TelegramAPIError
from aiogram.client.default import DefaultBotProperties
from aiogram.filters import Command
from aiogram.types import InlineKeyboardButton, InlineKeyboardMarkup

# –ò–º–ø–æ—Ä—Ç –æ—Å–Ω–æ–≤–Ω–æ–π –ª–æ–≥–∏–∫–∏ –ò–ò
from llm_core import (
    generate_text_stream,
    generate_text,
    generate_image,
    trim_history_by_tokens
)

# -------------------------------------------------------------------
# –õ–û–ì–ò–†–û–í–ê–ù–ò–ï
# -------------------------------------------------------------------
logger = logging.getLogger("neurozone_bot")
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
handler.setFormatter(logging.Formatter("%(asctime)s %(levelname)s %(message)s"))
logger.addHandler(handler)

def safe_log(user_id, event, extra=None):
    data = {"user_id": user_id, "event": event}
    if extra:
        data.update(extra)
    logger.info(data)

# -------------------------------------------------------------------
# –ü–ï–†–ï–ú–ï–ù–ù–´–ï –û–ö–†–£–ñ–ï–ù–ò–Ø
# -------------------------------------------------------------------
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
GROK_API_KEY = os.getenv("GROK_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

if not BOT_TOKEN:
    raise SystemExit("‚ùå BOT_TOKEN –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏")

# -------------------------------------------------------------------
# –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø aiogram 3.x
# -------------------------------------------------------------------
bot = Bot(
    token=BOT_TOKEN,
    default=DefaultBotProperties(parse_mode="HTML")
)
dp = Dispatcher()

# -------------------------------------------------------------------
# RATE-LIMIT
# -------------------------------------------------------------------
RATE_LIMIT_PER_MINUTE = 30
user_requests = defaultdict(lambda: deque())

def check_rate_limit(user_id: int) -> bool:
    now = time.time()
    dq = user_requests[user_id]
    while dq and dq[0] < now - 60:
        dq.popleft()
    if len(dq) >= RATE_LIMIT_PER_MINUTE:
        return False
    dq.append(now)
    return True

# -------------------------------------------------------------------
# –ò–°–¢–û–†–ò–Ø –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø
# -------------------------------------------------------------------
MAX_HISTORY_TOKENS_DEFAULT = 3000

user_state = defaultdict(lambda: {
    "mode": "text",
    "provider": "openai",
    "model": None,
    "history": [],
    "max_history_tokens": MAX_HISTORY_TOKENS_DEFAULT
})

def trim_user_history(uid: int):
    st = user_state[uid]
    st["history"] = trim_history_by_tokens(
        st["history"],
        st["max_history_tokens"]
    )

# -------------------------------------------------------------------
# –ú–û–î–ï–õ–ò (–∏–∑ —Ç–≤–æ–µ–≥–æ —Å—Ç–∞—Ä–æ–≥–æ bot.py)
# -------------------------------------------------------------------
openai_models = {
    "GPT-5": {"id": "gpt-5", "desc": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞ –∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."},
    "GPT-5 mini": {"id": "gpt-5-mini", "desc": "–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."},
    "GPT-5 nano": {"id": "gpt-5-nano", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."},
    "GPT-4.1": {"id": "gpt-4.1", "desc": "–°–∞–º–∞—è —É–º–Ω–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π."}
}

grok_models = {
    "Grok-code-fast-1": {"id": "grok-code-fast-1", "desc": "–ë—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è."},
    "Grok-4-fast-reasoning": {"id": "grok-4-fast-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."},
    "Grok-4-fast-non-reasoning": {"id": "grok-4-fast-non-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."}
}

gemini_models = {
    "Gemini 2.5 Flash": {"id": "gemini-2.5-flash", "desc": "–õ—É—á—à–∞—è –ø–æ —Ü–µ–Ω–µ/–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."},
    "Gemini 2.5 Flash-Lite": {"id": "gemini-2.5-flash-lite", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è flash-–º–æ–¥–µ–ª—å."}
}

# -------------------------------------------------------------------
# –ö–õ–ê–í–ò–ê–¢–£–†–´
# -------------------------------------------------------------------

def kb_main() -> InlineKeyboardMarkup:
    return InlineKeyboardMarkup(inline_keyboard=[
        [
            InlineKeyboardButton(text="–¢–µ–∫—Å—Ç", callback_data="mode:text"),
            InlineKeyboardButton(text="–ö–∞—Ä—Ç–∏–Ω–∫–∏", callback_data="mode:image")
        ],
        [
            InlineKeyboardButton(text="OpenAI", callback_data="provider:openai"),
            InlineKeyboardButton(text="Grok", callback_data="provider:grok"),
            InlineKeyboardButton(text="Gemini", callback_data="provider:gemini")
        ],
        [
            InlineKeyboardButton(text="–°–±—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏", callback_data="reset:history")
        ]
    ])

async def show_models_for_provider(cb: types.CallbackQuery, provider_key: str):
    """–ü–æ–∫–∞–∑ –º–æ–¥–µ–ª–µ–π —Å –æ–ø–∏—Å–∞–Ω–∏—è–º–∏."""
    uid = cb.from_user.id

    if provider_key == "openai":
        models_dict = openai_models
        header = "üîµ <b>OpenAI ‚Äî ChatGPT</b>"
    elif provider_key == "grok":
        models_dict = grok_models
        header = "üß† <b>Grok ‚Äî xAI</b>"
    else:
        models_dict = gemini_models
        header = "‚ö° <b>Gemini ‚Äî Google AI</b>"

    parts = [f"{header}\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:"]
    kb_rows = []

    for name, meta in models_dict.items():
        parts.append(f"\n<b>{name}</b> ‚Äî <i>{meta['desc']}</i>")
        kb_rows.append([
            InlineKeyboardButton(text=name, callback_data=f"model:{meta['id']}")
        ])

    kb_rows.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="back:providers")])

    txt = "\n".join(parts)

    try:
        await cb.message.edit_text(txt, reply_markup=InlineKeyboardMarkup(inline_keyboard=kb_rows))
    except:
        await cb.message.answer(txt, reply_markup=InlineKeyboardMarkup(inline_keyboard=kb_rows))

    await cb.answer()

# -------------------------------------------------------------------
# CALLBACK HANDLERS
# -------------------------------------------------------------------

@dp.message(Command("start", "help"))
async def start_cmd(message: types.Message):
    uid = message.from_user.id
    safe_log(uid, "start")
    await message.answer("–ü—Ä–∏–≤–µ—Ç! –í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã:", reply_markup=kb_main())

@dp.callback_query(lambda c: c.data and c.data.startswith("mode:"))
async def set_mode(cb: types.CallbackQuery):
    uid = cb.from_user.id
    mode = cb.data.split(":", 1)[1]
    user_state[uid]["mode"] = mode
    safe_log(uid, "mode_set", {"mode": mode})
    await cb.message.edit_text(
        f"–†–µ–∂–∏–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω: <b>{mode}</b>\n–¢–µ–ø–µ—Ä—å –≤—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞:",
        reply_markup=kb_main()
    )
    await cb.answer()

@dp.callback_query(lambda c: c.data and c.data.startswith("provider:"))
async def set_provider(cb: types.CallbackQuery):
    uid = cb.from_user.id
    provider = cb.data.split(":", 1)[1]
    user_state[uid]["provider"] = provider
    safe_log(uid, "provider_set", {"provider": provider})
    await show_models_for_provider(cb, provider)

@dp.callback_query(lambda c: c.data == "back:providers")
async def back_to_providers(cb: types.CallbackQuery):
    await cb.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º:", reply_markup=kb_main())
    await cb.answer()

@dp.callback_query(lambda c: c.data and c.data.startswith("model:"))
async def set_model(cb: types.CallbackQuery):
    uid = cb.from_user.id
    model_id = cb.data.split(":", 1)[1]
    user_state[uid]["model"] = model_id
    safe_log(uid, "model_set", {"model": model_id})
    await cb.message.edit_text(
        f"–í—ã –≤—ã–±—Ä–∞–ª–∏ –º–æ–¥–µ–ª—å:\n<b>{model_id}</b>\n\n–¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –≤–∞—à –∑–∞–ø—Ä–æ—Å.",
        reply_markup=kb_main()
    )
    await cb.answer()

@dp.callback_query(lambda c: c.data == "reset:history")
async def reset_history(cb: types.CallbackQuery):
    uid = cb.from_user.id
    user_state[uid]["history"] = []
    safe_log(uid, "history_reset")
    await cb.message.edit_text("üßπ –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞.", reply_markup=kb_main())
    await cb.answer()

# -------------------------------------------------------------------
# MESSAGE HANDLER
# -------------------------------------------------------------------

@dp.message()
async def on_message(message: types.Message):
    uid = message.from_user.id
    text = message.text or ""
    safe_log(uid, "message_received", {"chars": len(text)})

    if not check_rate_limit(uid):
        await message.answer("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏—Ç–µ –º–∏–Ω—É—Ç—É.")
        return

    st = user_state[uid]
    mode = st["mode"]
    provider = st["provider"]
    model = st["model"]

    # ----- IMAGE MODE -----
    if mode == "image":
        try:
            img_url = await generate_image(
                provider=provider,
                prompt=text,
                openai_key=OPENAI_API_KEY,
                grok_key=GROK_API_KEY
            )
            await message.answer_photo(img_url, caption="–ì–æ—Ç–æ–≤–æ!")

            st["history"].append({"role": "user", "content": "[image_prompt]"})
            st["history"].append({"role": "assistant", "content": "[image_generated]"})
            trim_user_history(uid)

        except Exception as e:
            safe_log(uid, "image_error", {"err": str(e)})
            await message.answer("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
        return

    # ----- TEXT MODE (STREAMING) -----
    st["history"].append({"role": "user", "content": text})
    trim_user_history(uid)

    status = await message.answer("–ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

    try:
        full = ""
        last_edit = time.time()

        stream = generate_text_stream(
            provider=provider,
            model=model,
            history=st["history"],
            user_input=text,
            openai_key=OPENAI_API_KEY,
            grok_key=GROK_API_KEY,
            gemini_key=GEMINI_API_KEY,
            max_history_tokens=st["max_history_tokens"]
        )

        async for chunk in stream:
            full += chunk
            if time.time() - last_edit >= 0.35:
                try:
                    await status.edit_text(full)
                except TelegramAPIError:
                    pass
                last_edit = time.time()

        try:
            await status.edit_text(full)
        except TelegramAPIError:
            pass

        st["history"].append({"role": "assistant", "content": full})
        trim_user_history(uid)

    except Exception as e:
        safe_log(uid, "stream_error", {"err": str(e)})

        try:
            fallback = await generate_text(
                provider=provider,
                model=model,
                history=st["history"],
                user_input=text,
                openai_key=OPENAI_API_KEY,
                grok_key=GROK_API_KEY,
                gemini_key=GEMINI_API_KEY,
                max_history_tokens=st["max_history_tokens"]
            )
            await status.edit_text(fallback)
        except:
            await status.edit_text("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –º–æ–¥–µ–ª–∏.")

# -------------------------------------------------------------------
# –ó–ê–ü–£–°–ö
# -------------------------------------------------------------------

async def main():
    logger.info("Bot started")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
