import os
import sys
import logging
import asyncio
import time
import openai
import google.generativeai as genai
import html  # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –±–∏–±–ª–∏–æ—Ç–µ–∫—É html
from xai_sdk import Client as XAI_Client
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from aiogram.types import InlineKeyboardMarkup, InlineKeyboardButton, Message
from aiogram.client.default import DefaultBotProperties
from dotenv import load_dotenv

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ ===
sys.stdout.reconfigure(encoding='utf-8')
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
load_dotenv()

# === –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ API ===
BOT_TOKEN = os.getenv("BOT_TOKEN")
openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
xai_client = XAI_Client(api_key=os.getenv("GROK_API_KEY"))
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

bot = Bot(token=BOT_TOKEN, default=DefaultBotProperties(parse_mode='HTML'))
dp = Dispatcher()

# === –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã ===
user_state = {}
MAX_HISTORY_LENGTH = 10

# === –ú–æ–¥–µ–ª–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
openai_models = { "GPT-5": {"id": "gpt-5", "desc": "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∞ –∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –∑–∞–¥–∞—á."}, "GPT-5 mini": {"id": "gpt-5-mini", "desc": "–ë–æ–ª–µ–µ –±—ã—Å—Ç—Ä–∞—è, —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."}, "GPT-5 nano": {"id": "gpt-5-nano", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –≤–µ—Ä—Å–∏—è."}, "GPT-4.1": {"id": "gpt-4.1", "desc": "–°–∞–º–∞—è —É–º–Ω–∞—è –º–æ–¥–µ–ª—å –±–µ–∑ —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π."}}
grok_models = {"Grok-code-fast-1": {"id": "grok-code-fast-1", "desc": "–ë—ã—Å—Ç—Ä–∞—è –∏ —ç–∫–æ–Ω–æ–º–∏—á–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è."}, "Grok-4-fast-reasoning": {"id": "grok-4-fast-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."}, "Grok-4-fast-non-reasoning": {"id": "grok-4-fast-non-reasoning", "desc": "–ü–æ—Å–ª–µ–¥–Ω–µ–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–µ –≤ —ç–∫–æ–Ω–æ–º–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö."}}
gemini_models = {"Gemini 2.5 Flash": {"id": "gemini-2.5-flash", "desc": "–õ—É—á—à–∞—è –ø–æ —Ü–µ–Ω–µ/–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."}, "Gemini 2.5 Flash-Lite": {"id": "gemini-2.5-flash-lite", "desc": "–°–∞–º–∞—è –±—ã—Å—Ç—Ä–∞—è flash-–º–æ–¥–µ–ª—å."}}

# === –ú–µ–Ω—é (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ===
def main_mode_menu():
    buttons = [[InlineKeyboardButton(text="‚úçÔ∏è –¢–µ–∫—Å—Ç–æ–≤—ã–π —á–∞—Ç", callback_data="mode_textchat")], [InlineKeyboardButton(text="üé® –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", callback_data="mode_imagegen")], [InlineKeyboardButton(text="üåê –°–∞–π—Ç", url="https://neurozone.pro/")], [InlineKeyboardButton(text="üîí –ü–æ–ª–∏—Ç–∏–∫–∞ –∫–æ–Ω—Ñ–∏–¥–µ–Ω—Ü–∏–∞–ª—å–Ω–æ—Å—Ç–∏", url="https://neurozone.pro/privacy")]]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
def text_provider_menu():
    buttons = [[InlineKeyboardButton(text="üí≠ ChatGPT (OpenAI)", callback_data="provider_openai")], [InlineKeyboardButton(text="üß† Grok (xAI)", callback_data="provider_grok")], [InlineKeyboardButton(text="‚ö° Gemini (Google)", callback_data="provider_gemini")], [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main_menu")]]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
def image_provider_menu():
    buttons = [[InlineKeyboardButton(text=" DALL-E 3 (OpenAI)", callback_data="image_provider_openai")], [InlineKeyboardButton(text=" Grok Image (xAI)", callback_data="image_provider_grok")], [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main_menu")]]
    return InlineKeyboardMarkup(inline_keyboard=buttons)
def reset_user_state(user_id):
    user_state[user_id] = {"provider": None, "model": None, "history": [], "mode": None}

# === –ù–æ–≤—ã–µ –º–µ–Ω—é –¥–ª—è –≤–æ–∑–≤—Ä–∞—Ç–∞ ===
def model_selected_menu():
    buttons = [
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –∫ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º", callback_data="back_to_provider")],
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main_menu")]
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)

def image_selected_menu():
    buttons = [
        [InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –≥–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é", callback_data="back_to_main_menu")]
    ]
    return InlineKeyboardMarkup(inline_keyboard=buttons)

# === –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥ –∏ –∫–Ω–æ–ø–æ–∫ ===
@dp.message(Command("start", "reset"))
async def start_reset_command(message: Message): reset_user_state(message.from_user.id); await message.answer("<b>üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç NeuroZone.</b>\n\n–í—ã–±–µ—Ä–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å:", reply_markup=main_mode_menu())
@dp.callback_query(lambda c: c.data == "back_to_main_menu")
async def back_to_main_menu_handler(callback_query: types.CallbackQuery): reset_user_state(callback_query.from_user.id); await callback_query.message.edit_text("<b>üëã –ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ –±–æ—Ç NeuroZone.</b>\n\n–í—ã–±–µ—Ä–∏—Ç–µ, —á—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å:", reply_markup=main_mode_menu())
@dp.callback_query(lambda c: c.data == "back_to_provider")
async def back_to_provider_handler(callback_query: types.CallbackQuery):
    user_id = callback_query.from_user.id
    if user_id in user_state:
        user_state[user_id]["model"] = None
        # user_state[user_id]["history"] = []  # –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: —Å–±—Ä–æ—Å –∏—Å—Ç–æ—Ä–∏–∏ –ø—Ä–∏ –≤–æ–∑–≤—Ä–∞—Ç–µ
    await callback_query.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞:", reply_markup=text_provider_menu())
@dp.callback_query(lambda c: c.data.startswith("mode_"))
async def mode_selection_handler(callback_query: types.CallbackQuery):
    mode = callback_query.data.split("_")[1]; user_id = callback_query.from_user.id;
    if user_id not in user_state: reset_user_state(user_id)
    user_state[user_id]["mode"] = mode
    if mode == "textchat": await callback_query.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞:", reply_markup=text_provider_menu())
    elif mode == "imagegen": await callback_query.message.edit_text("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π:", reply_markup=image_provider_menu())
@dp.callback_query(lambda c: c.data.startswith("provider_"))
async def text_provider_selection(callback_query: types.CallbackQuery):
    provider = callback_query.data.split("_")[1]; user_id = callback_query.from_user.id; user_state[user_id]["provider"] = provider; models_dict, header = {}, ""
    if provider == "openai": models_dict, header = openai_models, "üîπ <b>ChatGPT (OpenAI)</b>"
    elif provider == "grok": models_dict, header = grok_models, "üß† <b>Grok (xAI)</b>"
    elif provider == "gemini": models_dict, header = gemini_models, "‚ö° <b>Gemini (Google)</b>"
    text_parts = [f"{header}\n\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:"]; buttons = []
    for name, data in models_dict.items(): text_parts.append(f"\n<b>{name}</b> - <i>{data['desc']}</i>"); buttons.append([InlineKeyboardButton(text=name, callback_data=f"model_{data['id']}")])
    buttons.append([InlineKeyboardButton(text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data="mode_textchat")]); await callback_query.message.edit_text("\n".join(text_parts), reply_markup=InlineKeyboardMarkup(inline_keyboard=buttons))
@dp.callback_query(lambda c: c.data.startswith("model_"))
async def model_selection(callback_query: types.CallbackQuery):
    model_id = callback_query.data.split("_", 1)[1]; user_id = callback_query.from_user.id;
    if user_id not in user_state or not user_state[user_id].get("provider"): await callback_query.answer("–û—à–∏–±–∫–∞. –ù–∞—á–Ω–∏—Ç–µ —Å /start"); return
    user_state[user_id]["model"] = model_id; await callback_query.message.edit_text(f"‚úÖ –ú–æ–¥–µ–ª—å <b>{model_id}</b> –≤—ã–±—Ä–∞–Ω–∞.\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å.", reply_markup=model_selected_menu())
@dp.callback_query(lambda c: c.data.startswith("image_provider_"))
async def image_provider_selection(callback_query: types.CallbackQuery):
    provider = callback_query.data.split("_")[2]; user_id = callback_query.from_user.id
    if user_id not in user_state: reset_user_state(user_id)
    user_state[user_id]["provider"] = provider; provider_name = ""
    if provider == "openai": provider_name = "DALL-E 3 (OpenAI)"
    elif provider == "grok": provider_name = "Grok Image (xAI)"
    await callback_query.message.edit_text(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è: <b>{provider_name}</b>.\n\n–û—Ç–ø—Ä–∞–≤—å—Ç–µ –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏.", reply_markup=image_selected_menu())

# --- –ì–õ–ê–í–ù–´–ô –û–ë–†–ê–ë–û–¢–ß–ò–ö ---
@dp.message()
async def main_message_handler(message: Message):
    user_id = message.from_user.id
    if user_id not in user_state or not user_state[user_id].get("mode"): await message.answer("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —á–µ—Ä–µ–∑ /start"); return
    mode = user_state[user_id]["mode"]
    if mode == "textchat": await handle_text_chat(message)
    elif mode == "imagegen": await handle_image_generation(message)
    else: await message.answer("–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–∂–∏–º. –ù–∞—á–Ω–∏—Ç–µ —Å /start")

# --- –õ–æ–≥–∏–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —á–∞—Ç–∞ ---
async def handle_text_chat(message: Message):
    user_id = message.from_user.id; start_time = time.time(); provider = user_state[user_id]["provider"]; model_id = user_state[user_id]["model"]; user_input = message.text.strip(); history = user_state[user_id].get("history", []); answer = ""
    if not model_id: await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å."); return
    logging.info(f"Received text message from user_id: {user_id}"); await message.chat.do("typing")
    try:
        if provider == "openai":
            history.append({"role": "user", "content": user_input}); response = await openai_client.chat.completions.create(model=model_id, messages=history); answer = response.choices[0].message.content; history.append({"role": "assistant", "content": answer})
        elif provider == "grok":
            history.append({"role": "USER", "content": user_input})
            def _generate(): return xai_client.chat.create(model=model_id, messages=history).choices[0].message.content
            answer = await asyncio.to_thread(_generate); history.append({"role": "ASSISTANT", "content": answer})
        elif provider == "gemini":
            gemini_sdk_history = [{"role": "user" if msg["role"] == "user" else "model", "parts": [msg["content"]]} for msg in history]; gemini_model = genai.GenerativeModel(model_id); chat_session = gemini_model.start_chat(history=gemini_sdk_history); response = await chat_session.send_message_async(user_input); answer = response.text; history.append({"role": "user", "content": user_input}); history.append({"role": "assistant", "content": answer})
        duration = time.time() - start_time; logging.info(f"SUCCESS text chat for user_id: {user_id}. Provider: {provider}, Model: {model_id}. Duration: {duration:.2f}s")
    except Exception as e:
        duration = time.time() - start_time; logging.exception(f"ERROR during text chat for user_id: {user_id}. Provider: {provider}. Error: {e}")
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º html.escape
        answer = f"‚ùå <b>–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.</b>\n\n<pre>{html.escape(str(e))}</pre>"
    if len(history) > MAX_HISTORY_LENGTH * 2:  # –£—á–∏—Ç—ã–≤–∞—è –ø–∞—Ä—ã user-assistant
        history = history[-MAX_HISTORY_LENGTH * 2:]
    user_state[user_id]["history"] = history; await message.answer(answer)

# --- –õ–æ–≥–∏–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ---
async def handle_image_generation(message: Message):
    user_id = message.from_user.id; provider = user_state[user_id].get("provider")
    if not provider: await message.answer("–°–Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—é."); return
    prompt = message.text.strip(); logging.info(f"User {user_id} requested an image with provider '{provider}'."); await message.answer("üé® –°–æ–∑–¥–∞—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."); await message.chat.do("upload_photo")
    start_time = time.time()
    try:
        image_url, caption = "", ""
        if provider == "openai":
            response = await openai_client.images.generate(model="dall-e-3", prompt=prompt, n=1, size="1024x1024"); image_url = response.data[0].url; caption = f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç DALL-E 3:\n¬´{prompt}¬ª"
        elif provider == "grok":
            def _generate(): return xai_client.image.sample(model="grok-2-image-1212", prompt=prompt, image_format="url").url
            image_url = await asyncio.to_thread(_generate); caption = f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ—Ç Grok Image:\n¬´{prompt}¬ª"
        if image_url:
            duration = time.time() - start_time; logging.info(f"SUCCESS image generation for user_id: {user_id}. Provider: {provider}. Duration: {duration:.2f}s"); await message.answer_photo(photo=image_url, caption=caption)
        else: raise Exception("Provider logic is not implemented")
    except Exception as e:
        duration = time.time() - start_time; logging.exception(f"ERROR during image generation for user_id: {user_id}. Provider: {provider}")
        error_message = str(e)
        if isinstance(e, openai.BadRequestError) and e.body and 'message' in e.body:
             error_message = e.body['message']
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º html.escape
        await message.answer(f"‚ùå <b>–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.</b>\n\n<pre>{html.escape(error_message)}</pre>")

# --- –¢–û–ß–ö–ê –í–•–û–î–ê ---
async def main():
    if not BOT_TOKEN: logging.error("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏!"); return
    await bot.delete_webhook(drop_pending_updates=True)
    logging.info("ü§ñ –ë–æ—Ç –∑–∞–ø—É—â–µ–Ω")
    await bot.set_my_commands([types.BotCommand(command="start", description="–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞"), types.BotCommand(command="reset", description="–ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞")])
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())
